% !Rnw weave = knitr

\documentclass{article}


\usepackage[utf8]{inputenc}
\usepackage[cyr]{aeguill}
\usepackage[francais]{babel}


\begin{document}

\section*{Exercice 1}





<<echo=FALSE>>=
load("exo1.RData")
@

On centre tout d'abord la matrice X à l'aide de la matrice de centrage Q8, ça nous servira plus tard :
<<eval=FALSE>>=
X = Q8 %*% X
@
On calcule la matrice des distances euclidiennes D2 :
<<eval=FALSE>>=
D2 = as.matrix(dist(X))
D2 = D2^2
@
<<>>=
D2
@
Après avoir obtenu cette précieuse matrice, on peut calculer la matrice des produits scalaires de 2 façons :
<<>>=
W = X %*% t(X)
@

Mais normalement, on n'aurait pas accès à X directement, il faut la déduire de la matrice des distances euclidiennes :
<<>>=
W = (-1/2)*Q8 %*% D2 %*% Q8
@

Il reste à vérifier que W soit semi définie-positive, pour savoir si la matrice des distances était bien euclidienne :
<<>>=
L = eigen(W)$values
L
@
W est bien semi définie-positive, on va juste arrondir à zero les valeurs négatives très petites, et diagonaliser L :

<<>>=
L[L<0] = 0
L = diag(L)
L
@

Matrice des vecteurs propres :
<<>>=
V = eigen(W)$vectors
@






\begin{verbatim}


1. distX = as.matrix(X)
    distX = distX ^2
  
2. Méthode 1 
  XC = scale(X, scale=T)
  W = XC\%*\%t(XC)
  
  Méthode 2 
  QN = diag(nrow(X)) - matrix(1, nrow(X), nrow(X))/nrow(X)
  W = -1/2*QN\%*\%distX\%*\%QN
  
3. Pour vérifier si elle est définie semi-positive, il suffit de vérifier que les valeurs propres soient positives ce qui est le cas car on peut considérer que -1.37*10^-17 et -2.45*10^-16 sont des valeurs nulles. 
eigen(W)

4. L = eigen(W)$values
  L = diag(nrow(X))*L
  
  V = eigen(W)$vectors
  
5. C = V\%*\%sqrt(L)
  pas oublier de retirer les NaN
  
  plot(C)
  idem à biplot(princomp(X))
  
\end{verbatim}
  
\section*{Exercice 2}

\begin{verbatim}
m = as.vector(mutation)
b = cmdscale(mutation, 2, T)
c = as.vector(dist(b$points))
plot(b,c) problème mais on est pas loin 
qualité à calculer avec les valeurs propres b[,1]$eigen etc... / sum 

on refait de même avec cmdscale(mutation, 3, T) jusqu'à 5 

\end{verbatim}

\section*{Exercice 3} 



library(cluster)
clusplot 
\subsection*{Iris}

\begin{verbatim}
iris = iris[ ,1:4]
res2 = kmeans(iris, 2)
plot(iris, col= res2$cluster)
clusplot(iris, res2$cluster)i
res2 = kmeans(iris, 3)
> plot(iris, col= res2$cluster)

2 types différents : 143 ou 78.9 pour l'inertie des classes (tot.withinss)

$for(j in 2:10){
  for(i in 1:100){
    test[j, i] = kmeans(iris, j)$tot.withinss
  }
}$
apply(test, 2, min)
La solution qui apparait en 3 classes n'est pas flagrante avec le tableau des minimums des inerties. La méthode du coude ne fonctionne pas très bien, elle ne fait pas apparaitre de coude. Le minimum d'inertie de  fait que diminuer en fonction du nombre de classes. 
Une solution serait de pénaliser un grand nombre de classes par le nombre d'individus présents dans la classe.
\end{verbatim}

\subsection*{Crabs}

library(MASS)


\subsection*{Mutations}
\begin{verbatim}
res = kmeans(mutations2, 2)
plot(cmdscale(mutations), col=res$cluster)

Avec 3 vert au milieu des noirs 

4 cluster seulement un point dans le dernier

tableau de contingence pour comparer les partitions table(res$cluster, res2$cluster)
\end{verbatim}



\end{document}