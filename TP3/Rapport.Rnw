\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[cyr]{aeguill}
\usepackage[francais]{babel}

\begin{document}

\title{TP3: Discrimination, théorie bayésienne de la décision}
\author{Jean Baptiste Vivier - Marion Depuydt}
\maketitle
\section*{Classifieur euclidien, K plus proches voisins}

\subsection*{Programmation}

Voir code en annexe

\subsection*{Evaluation des performances}

\subsubsection*{Centre de gravité $ \mu_k $ et matrice de covariance $ \sum_k $ }

\section*{Annexe}

\subsection*{Classifieur euclidien: fonction d'apprentissage}
<<eval=FALSE>>=
ceuc.app <- function(Xapp, zapp){
  apply(Xapp, 2, by, zapp, mean)
}
@
\subsection*{Classifieur euclidien: fonction d'évaluation}
<<eval=FALSE>>=
ceuc.val <- function(mu, Xtst){
  sol <- matrix(nrow = nrow(Xtst))
  dist <- matrix(ncol = nrow(mu), nrow = nrow(Xtst))
  for(i in 1:nrow(Xtst)){
    for(j in 1:nrow(mu)){
      dist[i,j] <- sqrt(sum((Xtst[i,]-t(mu[j,]))^2))
    }
  }
  # choisir la colonne de la classe
  min <- apply(dist, 1, min)
  ntst <- vector('numeric', nrow(dist))
  for(i in 1:nrow(dist)){
    for(j in 1:ncol(dist)){
      if(min[i]==dist[i,j]){
        ntst[i] = j
      }
    }
  }
  ntst
}
@
\subsection*{KPPV: fonctions d'apprentissage du nombre optimal de voisins K}
<<eval=FALSE>>=
kppv.app <- function(Xapp, zapp, Xval, zval, nppv)
{
  for(i in nppv){
    min <- i
    erreur_opt <- 1
    tmp <- kppv.val(Xapp, zapp, i, Xval)
    erreur <- sum((tmp == zval)==TRUE)/length(zval)
    if(erreur_opt > erreur){
      erreur_opt <- erreur
      min <- i
    }
  }
  min
}
@
\subsection*{KPPV: fonctions d'évaluation suivant un K donné}
<<eval=FALSE>>=
kppv.val <- function(Xapp, zapp, K, Xtst)
{
  dist <- matrix(ncol = nrow(Xtst), nrow = nrow(Xapp))
  for(i in 1:nrow(Xtst)){
    for(j in 1:nrow(Xapp)){
      dist[j,i] <- sqrt(sum((Xtst[i,]-t(Xapp[j,]))^2))
    }
  }
  tmp <- apply(dist, 2, order)
  tmp2 <- tmp
  for(i in 1:ncol(tmp)){
    tmp2[,i] <- zapp[tmp[,i]]
  }
  tmp2 <- tmp2[1:K,]
  round(apply(tmp2, 2, mean))
}
@

\end{document}